import os
from flask import Flask, request
import telebot
from groq import Groq
from datetime import datetime, timedelta
import requests
from bs4 import BeautifulSoup
import time

# --- CONFIG ---
bot = telebot.TeleBot(os.environ.get('TELEGRAM_TOKEN'))
CHANNEL_ID = os.environ.get('TELEGRAM_CHAT_ID')
client = Groq(api_key=os.environ.get("GROQ_API_KEY"))

app = Flask(__name__)

# --- TRADE TRACKING ---
active_trades = {}  # {ticker: {'msg_id': int, 'direction': str, 'entry': float, 'timeframe': str}}

# --- CACHE SYSTEM ---
class NewsCache:
    def __init__(self, ttl_minutes=60):
        self.cache = {}
        self.ttl = ttl_minutes * 60  # Convert to seconds
        
    def get(self, key):
        """Retrieve cached data if still valid"""
        if key in self.cache:
            data, timestamp = self.cache[key]
            if time.time() - timestamp < self.ttl:
                print(f"âœ… Cache HIT for {key}")
                return data
            else:
                print(f"â° Cache EXPIRED for {key}")
                del self.cache[key]
        print(f"âŒ Cache MISS for {key}")
        return None
    
    def set(self, key, value):
        """Store data in cache with timestamp"""
        self.cache[key] = (value, time.time())
        print(f"ğŸ’¾ Cached {key} (expires in {self.ttl/60} min)")
    
    def clear(self):
        """Manually clear all cache"""
        self.cache = {}
        print("ğŸ—‘ï¸ Cache cleared")
    
    def get_stats(self):
        """Get cache statistics"""
        return {
            'items': len(self.cache),
            'ttl_minutes': self.ttl / 60
        }

# Initialize cache instances
news_cache = NewsCache(ttl_minutes=60)  # CPI news cached for 1 hour
mtf_cache = NewsCache(ttl_minutes=15)   # MTF data cached for 15 minutes

# --- CPI NEWS SCRAPER WITH CACHE ---
def get_cpi_bias():
    """
    Scrapes economic calendar for CPI and high-impact news
    Uses cache to avoid excessive requests
    """
    cache_key = 'cpi_news'
    
    # Try to get from cache first
    cached_data = news_cache.get(cache_key)
    if cached_data:
        return cached_data
    
    # Cache miss - fetch fresh data
    print("ğŸŒ Fetching fresh CPI news data...")
    
    # Try multiple sources with fallback
    result = scrape_investing_com() or scrape_forex_factory() or get_default_news()
    
    # Cache the result
    news_cache.set(cache_key, result)
    
    return result

def scrape_investing_com():
    """Primary news source: Investing.com"""
    try:
        url = "https://www.investing.com/economic-calendar/"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=8)
        if response.status_code != 200:
            print(f"âŒ Investing.com failed: {response.status_code}")
            return None
            
        soup = BeautifulSoup(response.content, 'html.parser')
        events = soup.find_all('tr', {'class': 'js-event-item'})
        
        high_risk_events = []
        
        for event in events[:25]:  # Check next 25 events
            try:
                # Check for high impact (3 bull icons)
                impact = event.find('td', {'class': 'sentiment'})
                if impact and len(impact.find_all('i', {'class': 'grayFullBullishIcon'})) == 3:
                    
                    event_name_elem = event.find('td', {'class': 'event'})
                    if event_name_elem:
                        name_text = event_name_elem.get_text(strip=True)
                        
                        # Priority keywords
                        if any(kw in name_text.upper() for kw in ['CPI', 'NFP', 'FOMC', 'GDP', 'INTEREST RATE', 'EMPLOYMENT']):
                            high_risk_events.append(name_text)
            except Exception as e:
                continue
        
        if high_risk_events:
            event_list = ", ".join(high_risk_events[:2])  # Top 2 events
            return {
                'status': 'HIGH_RISK',
                'message': f"âš ï¸ {high_risk_events[0][:35]}",
                'adjust': -10,
                'source': 'Investing.com',
                'events': high_risk_events
            }
        
        return {
            'status': 'CLEAR',
            'message': 'âœ… No major events',
            'adjust': 0,
            'source': 'Investing.com',
            'events': []
        }
        
    except Exception as e:
        print(f"âŒ Investing.com error: {e}")
        return None

def scrape_forex_factory():
    """Fallback source: Forex Factory"""
    try:
        url = "https://www.forexfactory.com/calendar?week=this"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=8)
        if response.status_code != 200:
            print(f"âŒ Forex Factory failed: {response.status_code}")
            return None
            
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Find high impact events (red icons)
        high_impact = soup.find_all('span', {'class': 'high'})
        
        cpi_events = []
        for event in high_impact[:15]:
            row = event.find_parent('tr')
            if row:
                title_elem = row.find('span', {'class': 'calendar__event-title'})
                if title_elem:
                    event_text = title_elem.get_text(strip=True)
                    if any(kw in event_text.upper() for kw in ['CPI', 'NFP', 'FOMC']):
                        cpi_events.append(event_text)
        
        if cpi_events:
            return {
                'status': 'CPI_ALERT',
                'message': f'ğŸš¨ {cpi_events[0][:35]}',
                'adjust': -15,
                'source': 'Forex Factory',
                'events': cpi_events
            }
        
        return {
            'status': 'CLEAR',
            'message': 'âœ… Safe window',
            'adjust': 0,
            'source': 'Forex Factory',
            'events': []
        }
        
    except Exception as e:
        print(f"âŒ Forex Factory error: {e}")
        return None

def get_default_news():
    """Fallback when all scrapers fail"""
    return {
        'status': 'UNKNOWN',
        'message': 'ğŸ“Š News check unavailable',
        'adjust': -5,
        'source': 'Default',
        'events': []
    }

# --- MULTI-TIMEFRAME CORRELATION WITH CACHE ---
def get_mtf_correlation(ticker, current_tf):
    """
    Analyzes multi-timeframe confluence
    Uses cache to avoid recalculating frequently
    """
    cache_key = f'mtf_{ticker}_{current_tf}'
    
    # Check cache
    cached_data = mtf_cache.get(cache_key)
    if cached_data:
        return cached_data
    
    print(f"ğŸ” Calculating MTF correlation for {ticker} on {current_tf}")
    
    # Timeframe hierarchy
    tf_hierarchy = {
        '1m': 1, '5m': 2, '15m': 3, '30m': 4, 
        '1h': 5, '4h': 6, '1d': 7, '1w': 8
    }
    
    current_level = tf_hierarchy.get(current_tf, 3)
    
    # Calculate confluence score
    if current_level <= 2:  # 1m, 5m - Very low TFs
        result = {
            'confluence': 'WEAK',
            'message': 'âš ï¸ Scalp setup - high risk',
            'boost': -5,
            'timeframe_quality': 'LOW'
        }
    elif current_level <= 3:  # 15m - Low TF
        result = {
            'confluence': 'MODERATE',
            'message': 'ğŸ“Š Check 1H trend',
            'boost': 0,
            'timeframe_quality': 'MEDIUM'
        }
    elif current_level <= 5:  # 30m, 1h - Medium TFs
        result = {
            'confluence': 'GOOD',
            'message': 'âœ… Medium-term aligned',
            'boost': 5,
            'timeframe_quality': 'GOOD'
        }
    else:  # 4h, 1d, 1w - High TFs
        result = {
            'confluence': 'STRONG',
            'message': 'ğŸ¯ Higher TF confirmation',
            'boost': 10,
            'timeframe_quality': 'EXCELLENT'
        }
    
    # Cache the result
    mtf_cache.set(cache_key, result)
    
    return result

# --- ENHANCED AI ANALYSIS ---
def get_ai_analysis(data):
    """
    Comprehensive AI analysis using cached news and MTF data
    """
    strat = data.get('strat', 'Unknown')
    ticker = data.get('ticker')
    tf = data.get('tf', 'N/A')
    direction = data.get('sig', 'N/A')
    entry_price = data.get('price', 'N/A')
    sl = data.get('sl', 'N/A')
    tp3 = data.get('tp3', 'N/A')
    
    # Base win probability from strategy type
    strategy_probabilities = {
        'Triangle Breakout': 80,
        'Triangle Breakdown': 80,
        'Range Bounce': 70,
        'Range Rejection': 70,
        'Scalp MA Cross': 45
    }
    
    base_prob = strategy_probabilities.get(strat, 50)
    
    # Get cached news data
    cpi_data = get_cpi_bias()
    
    # Get cached MTF data
    mtf_data = get_mtf_correlation(ticker, tf)
    
    # Calculate final probability with adjustments
    final_prob = base_prob + cpi_data['adjust'] + mtf_data['boost']
    final_prob = max(30, min(95, final_prob))  # Cap between 30-95%
    
    # Calculate R:R ratio
    try:
        entry = float(entry_price)
        stop = float(sl)
        target = float(tp3)
        risk = abs(entry - stop)
        reward = abs(target - entry)
        rr_ratio = round(reward / risk, 1) if risk > 0 else 0
    except:
        rr_ratio = 3.0
    
    # Enhanced AI prompt
    prompt = f"""
You are an elite institutional forex trader. Analyze this setup with precision:

**TRADE DETAILS:**
Pair: {ticker}
Direction: {direction}
Strategy: {strat} (Historical Win Rate: {base_prob}%)
Timeframe: {tf}
Entry: {entry_price}
Risk:Reward: 1:{rr_ratio}

**MARKET INTELLIGENCE:**
News Risk: {cpi_data['message']} (Source: {cpi_data['source']})
Multi-Timeframe: {mtf_data['message']}
Adjusted Win Probability: {final_prob}%

**ANALYSIS TASK:**
Rate this trade 1-10 based on:
1. Strategy edge ({strat})
2. News risk exposure
3. Multi-timeframe confluence
4. Risk:reward profile (1:{rr_ratio})

**OUTPUT FORMAT (STRICT):**
Win Probability: {final_prob}%
Trade Rating: X/10
Bias: [One concise sentence: direction bias + key risk factor]

Keep response under 150 characters for the bias.
"""
    
    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=250
        )
        ai_text = completion.choices[0].message.content.strip()
        
        return {
            'analysis': ai_text,
            'cpi_status': cpi_data['message'],
            'mtf_status': mtf_data['message'],
            'final_prob': final_prob,
            'rr_ratio': rr_ratio,
            'news_source': cpi_data['source']
        }
    except Exception as e:
        print(f"AI Error: {e}")
        return {
            'analysis': f"Win Probability: {final_prob}%\nTrade Rating: 7/10\nBias: {strat} setup with {mtf_data['timeframe_quality']} TF quality.",
            'cpi_status': cpi_data['message'],
            'mtf_status': mtf_data['message'],
            'final_prob': final_prob,
            'rr_ratio': rr_ratio,
            'news_source': cpi_data.get('source', 'Unknown')
        }

# --- WEBHOOK HANDLER ---
@app.route('/webhook', methods=['POST'])
def webhook():
    try:
        data = request.json
        if not data:
            return 'No Data', 400

        ticker = data.get('ticker', 'UNKNOWN')
        
        # ===== HANDLE BREAK-EVEN UPDATE =====
        if data.get("status") == "MOVED TO BE":
            msg = (
                f"ğŸ›¡ï¸ *BREAK-EVEN SECURED*\n"
                f"{'â•' * 25}\n"
                f"ğŸ’± {ticker}\n"
                f"ğŸ“ Stop Loss â†’ Entry Price\n"
                f"ğŸ’° Current: `{data.get('price')}`\n"
                f"âœ… Risk eliminated!"
            )
            
            if ticker in active_trades:
                bot.send_message(
                    CHANNEL_ID, msg, parse_mode='Markdown',
                    reply_to_message_id=active_trades[ticker]['msg_id']
                )
            else:
                bot.send_message(CHANNEL_ID, msg, parse_mode='Markdown')
            
            return 'OK', 200
        
        # ===== HANDLE TP/SL HITS =====
        if "hit" in data:
            hit_msg = data.get('hit')
            price = data.get('price', 'N/A')
            
            # Determine outcome type
            if "TP3" in hit_msg:
                emoji, status, color = "ğŸ¯ğŸš€ğŸ’°", "MAXIMUM PROFIT", "JACKPOT"
            elif "TP2" in hit_msg:
                emoji, status, color = "ğŸ’âœ…", "STRONG WIN", "EXCELLENT"
            elif "TP1" in hit_msg:
                emoji, status, color = "âœ…ğŸ’µ", "PROFIT LOCKED", "GOOD"
            elif "SL" in hit_msg:
                emoji, status, color = "â›”ï¸âŒ", "STOPPED OUT", "LOSS"
            else:
                emoji, status, color = "ğŸ“Š", "UPDATE", "INFO"
            
            msg = (
                f"{emoji} *{status}*\n"
                f"{'â•' * 25}\n"
                f"ğŸ’± {ticker}\n"
                f"ğŸ“ {hit_msg}\n"
                f"ğŸ’° Exit Price: `{price}`\n"
                f"{'â•' * 25}"
            )
            
            if ticker in active_trades:
                bot.send_message(
                    CHANNEL_ID, msg, parse_mode='Markdown',
                    reply_to_message_id=active_trades[ticker]['msg_id']
                )
                
                # Clean up completed trades
                if "TP3" in hit_msg or "SL" in hit_msg:
                    print(f"ğŸ—‘ï¸ Removing {ticker} from active trades")
                    del active_trades[ticker]
            else:
                bot.send_message(CHANNEL_ID, msg, parse_mode='Markdown')
            
            return 'OK', 200

        # ===== NEW SIGNAL WITH CACHED ANALYSIS =====
        print(f"ğŸ“Š Processing new signal for {ticker}")
        ai_result = get_ai_analysis(data)
        
        signal_emoji = "ğŸŸ¢" if data.get('sig') == 'BUY' else "ğŸ”´"
        direction_arrow = "ğŸ“ˆ" if data.get('sig') == 'BUY' else "ğŸ“‰"
        
        msg = (
            f"{signal_emoji} *AAD-FX PREMIUM SIGNAL* {direction_arrow}\n"
            f"{'â•' * 30}\n"
            f"ğŸ’± *{data.get('ticker')}* | â° {data.get('tf')}\n"
            f"ğŸ¯ Strategy: {data.get('strat')}\n"
            f"{'â”€' * 30}\n"
            f"ğŸ“ *{data.get('sig')}* @ `{data.get('price')}`\n"
            f"ğŸ›‘ Stop Loss: `{data.get('sl')}`\n"
            f"{'â”€' * 30}\n"
            f"ğŸ¯ TP1: `{data.get('tp1')}`\n"
            f"ğŸ’ TP2: `{data.get('tp2')}`\n"
            f"ğŸš€ TP3: `{data.get('tp3')}`\n"
            f"ğŸ’° R:R = 1:{ai_result['rr_ratio']}\n"
            f"{'â•' * 30}\n"
            f"ğŸ§  *AI ANALYSIS*\n"
            f"{ai_result['analysis']}\n"
            f"{'â”€' * 30}\n"
            f"ğŸ“° News: {ai_result['cpi_status']}\n"
            f"ğŸ“Š MTF: {ai_result['mtf_status']}\n"
            f"{'â•' * 30}\n"
            f"â° {datetime.now().strftime('%H:%M UTC')} | ğŸ“¡ Cached"
        )
        
        sent_msg = bot.send_message(CHANNEL_ID, msg, parse_mode='Markdown')
        
        # Store trade for future updates
        active_trades[ticker] = {
            'msg_id': sent_msg.message_id,
            'direction': data.get('sig'),
            'entry': data.get('price'),
            'timeframe': data.get('tf'),
            'timestamp': datetime.now()
        }
        
        print(f"âœ… Signal sent and tracked: {ticker} (msg_id: {sent_msg.message_id})")
        
        return 'OK', 200
        
    except Exception as e:
        print(f"âŒ Webhook Error: {e}")
        import traceback
        traceback.print_exc()
        return 'Error', 500

# ===== ADMIN ENDPOINTS (OPTIONAL) =====
@app.route('/cache/stats', methods=['GET'])
def cache_stats():
    """Check cache statistics"""
    return {
        'news_cache': news_cache.get_stats(),
        'mtf_cache': mtf_cache.get_stats(),
        'active_trades': len(active_trades)
    }

@app.route('/cache/clear', methods=['POST'])
def clear_cache():
    """Manually clear cache (useful for testing)"""
    news_cache.clear()
    mtf_cache.clear()
    return {'status': 'Cache cleared successfully'}

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return {
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'active_trades': len(active_trades)
    }

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    print(f"ğŸš€ Starting AAD-FX Bot on port {port}")
    print(f"ğŸ“Š Cache TTL: News={news_cache.ttl/60}min, MTF={mtf_cache.ttl/60}min")
    app.run(host='0.0.0.0', port=port)
```

---

## **ğŸ“Š How the Cache System Works**

### **Cache Flow:**
```
User Request â†’ Check Cache â†’ Cache Hit? 
                              â†“
                         YES âœ… â†’ Return Cached Data (Fast!)
                              â†“
                         NO âŒ â†’ Scrape Website â†’ Store in Cache â†’ Return Data
```

### **Cache Benefits:**
- âš¡ **Faster responses** (cached data returns in <1ms)
- ğŸŒ **Fewer API calls** (reduces scraping load)
- ğŸ›¡ï¸ **Fallback protection** (if scraping fails, cache serves old data)
- ğŸ’° **Free tier friendly** (won't exceed rate limits)

---

## **ğŸ¯ Cache Statistics**

### **Visit these URLs to monitor your bot:**

1. **Health Check:**
```
https://your-app.onrender.com/health